{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow import keras\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10115113018204780330\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4139778048\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17093194522853905634\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:08:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 87000 files belonging to 29 classes.\n",
      "Using 69600 files for training.\n",
      "Found 87000 files belonging to 29 classes.\n",
      "Using 17400 files for validation.\n"
     ]
    }
   ],
   "source": [
    "ds_train = tf.keras.utils.image_dataset_from_directory(\"asl_alphabet_train\", image_size=(200,200), seed=128, validation_split=0.2, subset=\"training\")\n",
    "ds_test = tf.keras.utils.image_dataset_from_directory(\"asl_alphabet_train\", image_size=(200,200), seed=128, validation_split=0.2, subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PrefetchDataset' object has no attribute 'class_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2208\\1140107353.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclass_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mds_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'PrefetchDataset' object has no attribute 'class_names'"
     ]
    }
   ],
   "source": [
    "#class_names = ds_train\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in ds_train.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'class_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2208\\2998283717.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mds_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mds_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mnum_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'class_names' is not defined"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "ds_train = ds_train.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "ds_test = ds_test.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "num_labels = len(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "   tf.keras.layers.Rescaling(1./255),\n",
    "   tf.keras.layers.AveragePooling2D(6,3, input_shape=(200,200,1)),\n",
    "   tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "   tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "   tf.keras.layers.MaxPool2D(2,2),\n",
    "   tf.keras.layers.Dropout(0.5),\n",
    "   tf.keras.layers.Flatten(),\n",
    "   tf.keras.layers.Dense(128, activation='relu'),\n",
    "   tf.keras.layers.Dense(num_labels, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2175/2175 [==============================] - 569s 253ms/step - loss: 1.0774 - accuracy: 0.6733 - val_loss: 0.3072 - val_accuracy: 0.9037\n",
      "Epoch 2/5\n",
      "2175/2175 [==============================] - 481s 221ms/step - loss: 0.2986 - accuracy: 0.9007 - val_loss: 0.1975 - val_accuracy: 0.9432\n",
      "Epoch 3/5\n",
      "2175/2175 [==============================] - 471s 217ms/step - loss: 0.1870 - accuracy: 0.9365 - val_loss: 0.0732 - val_accuracy: 0.9772\n",
      "Epoch 4/5\n",
      "2175/2175 [==============================] - 456s 210ms/step - loss: 0.1334 - accuracy: 0.9536 - val_loss: 0.0624 - val_accuracy: 0.9796\n",
      "Epoch 5/5\n",
      "2175/2175 [==============================] - 457s 210ms/step - loss: 0.1109 - accuracy: 0.9623 - val_loss: 0.0536 - val_accuracy: 0.9831\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(ds_train, validation_data=ds_test, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case we lose the history of this run, it took 40 minutes to fit the model with the default layers we have. Here is the data:\n",
    "\n",
    "Epoch 1/5\n",
    "\n",
    "2175/2175 [==============================] - 569s 253ms/step - loss: 1.0774 - accuracy: 0.6733 - val_loss: 0.3072 - val_accuracy: 0.9037\n",
    "\n",
    "Epoch 2/5\n",
    "\n",
    "2175/2175 [==============================] - 481s 221ms/step - loss: 0.2986 - accuracy: 0.9007 - val_loss: 0.1975 - val_accuracy: 0.9432\n",
    "\n",
    "Epoch 3/5\n",
    "\n",
    "2175/2175 [==============================] - 471s 217ms/step - loss: 0.1870 - accuracy: 0.9365 - val_loss: 0.0732 - val_accuracy: 0.9772\n",
    "\n",
    "Epoch 4/5\n",
    "\n",
    "2175/2175 [==============================] - 456s 210ms/step - loss: 0.1334 - accuracy: 0.9536 - val_loss: 0.0624 - val_accuracy: 0.9796\n",
    "\n",
    "Epoch 5/5\n",
    "\n",
    "2175/2175 [==============================] - 457s 210ms/step - loss: 0.1109 - accuracy: 0.9623 - val_loss: 0.0536 - val_accuracy: 0.9831"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: asl_trained_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: asl_trained_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"asl_trained_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the summary of the model before we save it off so we can compare it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 200, 200, 3)       0         \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 65, 65, 3)        0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 63, 63, 64)        1792      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 61, 61, 32)        18464     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 30, 30, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 30, 30, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 28800)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3686528   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 29)                3741      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,710,525\n",
      "Trainable params: 3,710,525\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 200, 200, 3)       0         \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 65, 65, 3)        0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 63, 63, 64)        1792      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 61, 61, 32)        18464     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 30, 30, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 30, 30, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 28800)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3686528   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 29)                3741      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,710,525\n",
      "Trainable params: 3,710,525\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "saved_model = tf.keras.models.load_model('asl_trained_model')\n",
    "\n",
    "# Check its architecture\n",
    "saved_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking to evaluate using this doc:\n",
    "\n",
    "https://www.tensorflow.org/tutorials/keras/save_and_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28 files belonging to 28 classes.\n"
     ]
    }
   ],
   "source": [
    "ds_val = tf.keras.utils.image_dataset_from_directory(\"asl_alphabet_test\", image_size=(200,200), seed=128, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 3.1103 - accuracy: 0.9286 - 66ms/epoch - 66ms/step\n",
      "Restored model, accuracy: 92.86%\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "(28, 29)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the restored model\n",
    "loss, acc = saved_model.evaluate(ds_val, verbose=2)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
    "\n",
    "print(saved_model.predict(ds_val).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544/544 [==============================] - 31s 57ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.84525099e-17, 6.42273787e-22, 4.18394936e-22, ...,\n",
       "        1.16759565e-20, 1.00000000e+00, 1.25677517e-13],\n",
       "       [2.55495097e-17, 5.73135156e-25, 1.50758037e-25, ...,\n",
       "        1.20913074e-18, 1.02943357e-19, 3.78049182e-13],\n",
       "       [9.99952435e-01, 4.52070187e-11, 2.82039669e-10, ...,\n",
       "        2.10870043e-17, 7.03916831e-16, 1.75853599e-23],\n",
       "       ...,\n",
       "       [1.15425980e-24, 1.10750742e-16, 5.78126167e-34, ...,\n",
       "        5.15789828e-17, 9.15353348e-20, 8.60402537e-22],\n",
       "       [1.27072045e-13, 4.58209669e-19, 5.36165253e-12, ...,\n",
       "        1.37755638e-12, 7.30749882e-17, 1.07270370e-14],\n",
       "       [4.19023838e-09, 1.01764845e-05, 2.09307135e-03, ...,\n",
       "        1.51602013e-29, 5.47212898e-32, 8.78184934e-31]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model.predict(ds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://d2l.ai/chapter_convolutional-modern/alexnet.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess Images: https://towardsdatascience.com/implementing-alexnet-cnn-architecture-using-tensorflow-2-0-and-keras-2113e090ad98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(image, label):\n",
    "    # Normalize images to have a mean of 0 and standard deviation of 1\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    # Resize images from 32x32 to 277x277\n",
    "    image = tf.image.resize(image, (227,227))\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_sz = tf.data.experimental.cardinality(ds_train).numpy()\n",
    "ds_test_sz = tf.data.experimental.cardinality(ds_test).numpy()\n",
    "ds_train = (ds_train.cache()\n",
    "                  .prefetch(buffer_size=AUTOTUNE)\n",
    "                  .map(process_images)\n",
    "                  .shuffle(buffer_size=ds_train_sz)\n",
    "                  .batch(batch_size=32, drop_remainder=True))\n",
    "ds_test = (ds_test.cache()\n",
    "                  .prefetch(buffer_size=AUTOTUNE)\n",
    "                  .map(process_images)\n",
    "                  .shuffle(buffer_size=ds_test_sz)\n",
    "                  .batch(batch_size=32, drop_remainder=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 29\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=96, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=(227,227,3)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    tf.keras.layers.Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    tf.keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1, 1), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1, 1), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1, 1), padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_labels, activation='softmax')\n",
    "])\n",
    "\n",
    "lr = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.1, 10000, 0.90, staircase=False,\n",
    ")\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adam(\n",
    "#     learning_rate=lr,\n",
    "#     weight_decay=0.0005\n",
    "# )\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False,\n",
    "    name=\"Adam\",\n",
    ")\n",
    "model.compile(optimizer=tf.optimizers.SGD(learning_rate=0.001),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "2175/2175 [==============================] - 1895s 863ms/step - loss: 15.3194 - accuracy: 0.0340 - val_loss: 15.2303 - val_accuracy: 0.0366\n",
      "Epoch 2/75\n",
      "2175/2175 [==============================] - 1882s 865ms/step - loss: 15.3170 - accuracy: 0.0340 - val_loss: 15.2303 - val_accuracy: 0.0366\n",
      "Epoch 3/75\n",
      "2175/2175 [==============================] - 1723s 792ms/step - loss: 15.3168 - accuracy: 0.0340 - val_loss: 15.2303 - val_accuracy: 0.0366\n",
      "Epoch 4/75\n",
      "2175/2175 [==============================] - 1654s 761ms/step - loss: 15.4936 - accuracy: 0.0340 - val_loss: 15.5030 - val_accuracy: 0.0366\n",
      "Epoch 5/75\n",
      "2175/2175 [==============================] - 1647s 757ms/step - loss: 15.5751 - accuracy: 0.0340 - val_loss: 15.5030 - val_accuracy: 0.0366\n",
      "Epoch 6/75\n",
      "2175/2175 [==============================] - 1660s 763ms/step - loss: 15.5825 - accuracy: 0.0340 - val_loss: 15.5030 - val_accuracy: 0.0366\n",
      "Epoch 7/75\n",
      "2175/2175 [==============================] - 1659s 763ms/step - loss: 15.5747 - accuracy: 0.0340 - val_loss: 15.5030 - val_accuracy: 0.0366\n",
      "Epoch 8/75\n",
      "2175/2175 [==============================] - 1691s 777ms/step - loss: 15.5780 - accuracy: 0.0340 - val_loss: 15.5030 - val_accuracy: 0.0366\n",
      "Epoch 9/75\n",
      "2175/2175 [==============================] - 1668s 767ms/step - loss: 15.5767 - accuracy: 0.0340 - val_loss: 15.5030 - val_accuracy: 0.0366\n",
      "Epoch 10/75\n",
      "2175/2175 [==============================] - 1686s 775ms/step - loss: 15.5831 - accuracy: 0.0340 - val_loss: 15.5030 - val_accuracy: 0.0366\n",
      "Epoch 11/75\n",
      "2175/2175 [==============================] - 1665s 765ms/step - loss: 15.5829 - accuracy: 0.0340 - val_loss: 15.5030 - val_accuracy: 0.0366\n",
      "Epoch 12/75\n",
      "2175/2175 [==============================] - 1668s 767ms/step - loss: 15.5773 - accuracy: 0.0340 - val_loss: 15.5030 - val_accuracy: 0.0366\n",
      "Epoch 13/75\n",
      "2175/2175 [==============================] - 1721s 791ms/step - loss: 15.5844 - accuracy: 0.0340 - val_loss: 15.5030 - val_accuracy: 0.0366\n",
      "Epoch 14/75\n",
      "2175/2175 [==============================] - 1726s 794ms/step - loss: 15.5791 - accuracy: 0.0340 - val_loss: 15.5030 - val_accuracy: 0.0366\n",
      "Epoch 15/75\n",
      "2175/2175 [==============================] - 1731s 796ms/step - loss: 15.5805 - accuracy: 0.0340 - val_loss: 15.5030 - val_accuracy: 0.0366\n",
      "Epoch 16/75\n",
      " 360/2175 [===>..........................] - ETA: 22:33 - loss: 15.5777 - accuracy: 0.0345"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28536\\2431569461.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mds_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m75\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Python379\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python379\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1562\u001b[0m                         ):\n\u001b[0;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python379\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python379\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python379\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python379\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2496\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2497\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2499\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python379\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1861\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1862\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1863\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python379\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    505\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\Python379\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(ds_train, validation_data=ds_test, epochs=75, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 1/75\n",
    "2175/2175 [==============================] - 1895s 863ms/step - loss: 15.3194 - accuracy: 0.0340 - val_loss: 15.2303 - val_accuracy: 0.0366\n",
    "Epoch 2/75\n",
    "2175/2175 [==============================] - 1882s 865ms/step - loss: 15.3170 - accuracy: 0.0340 - val_loss: 15.2303 - val_accuracy: 0.0366\n",
    "Epoch 3/75\n",
    "2175/2175 [==============================] - 1723s 792ms/step - loss: 15.3168 - accuracy: 0.0340 - val_loss: 15.2303 - val_accuracy: 0.0366\n",
    "Epoch 4/75\n",
    "2175/2175 [==============================] - 1654s 761ms/step - loss: 15.4936 - accuracy: 0.0340 - val_loss: 15.5030 - val_accuracy: 0.0366\n",
    "Epoch 5/75\n",
    "2175/2175 [==============================] - 1647s 757ms/step - loss: 15.5751 - accuracy: 0.0340 - val_loss: 15.5030 - val_accuracy: 0.0366\n",
    "Epoch 6/75\n",
    "2175/2175 [==============================] - 1660s 763ms/step - loss: 15.5825 - accuracy: 0.0340 - val_loss: 15.5030 - val_accuracy: 0.0366\n",
    "Epoch 7/75\n",
    "2175/2175 [==============================] - 1659s 763ms/step - loss: 15.5747 - accuracy: 0.0340 - val_loss: 15.5030 - val_accuracy: 0.0366\n",
    "Epoch 8/75\n",
    "2175/2175 [==============================] - 1691s 777ms/step - loss: 15.5780 - accuracy: 0.0340 - val_loss: 15.5030 - val_accuracy: 0.0366\n",
    "Epoch 9/75\n",
    "2175/2175 [==============================] - 1668s 767ms/step - loss: 15.5767 - accuracy: 0.0340 - val_loss: 15.5030 - val_accuracy: 0.0366\n",
    "Epoch 10/75\n",
    "2175/2175 [==============================] - 1686s 775ms/step - loss: 15.5831 - accuracy: 0.0340 - val_loss: 15.5030 - val_accuracy: 0.0366\n",
    "Epoch 11/75\n",
    "2175/2175 [==============================] - 1665s 765ms/step - loss: 15.5829 - accuracy: 0.0340 - val_loss: 15.5030 - val_accuracy: 0.0366\n",
    "Epoch 12/75\n",
    "2175/2175 [==============================] - 1668s 767ms/step - loss: 15.5773 - accuracy: 0.0340 - val_loss: 15.5030 - val_accuracy: 0.0366\n",
    "Epoch 13/75\n",
    "2175/2175 [==============================] - 1721s 791ms/step - loss: 15.5844 - accuracy: 0.0340 - val_loss: 15.5030 - val_accuracy: 0.0366\n",
    "Epoch 14/75\n",
    "2175/2175 [==============================] - 1726s 794ms/step - loss: 15.5791 - accuracy: 0.0340 - val_loss: 15.5030 - val_accuracy: 0.0366\n",
    "Epoch 15/75\n",
    "2175/2175 [==============================] - 1731s 796ms/step - loss: 15.5805 - accuracy: 0.0340 - val_loss: 15.5030 - val_accuracy: 0.0366\n",
    "Epoch 16/75\n",
    " 360/2175 [===>..........................] - ETA: 22:33 - loss: 15.5777 - accuracy: 0.0345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Alex_Net_asl_trained_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Alex_Net_asl_trained_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"Alex_Net_asl_trained_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 48, 48, 96)        34944     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 23, 23, 96)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 23, 23, 256)       614656    \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 11, 11, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 11, 11, 384)       885120    \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 11, 11, 384)       1327488   \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 11, 11, 256)       884992    \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 5, 5, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4096)              26218496  \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 29)                118813    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46,865,821\n",
      "Trainable params: 46,865,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "saved_model = tf.keras.models.load_model('Alex_Net_asl_trained_model')\n",
    "\n",
    "# Check its architecture\n",
    "saved_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 15.4898 - accuracy: 0.0357 - 252ms/epoch - 252ms/step\n",
      "Restored model, accuracy:  3.57%\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "(28, 29)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the restored model\n",
    "loss, acc = saved_model.evaluate(ds_val, verbose=2)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
    "\n",
    "print(saved_model.predict(ds_val).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://www.analyticsvidhya.com/blog/2021/08/how-to-code-your-resnet-from-scratch-in-tensorflow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(x, filter):\n",
    "    # copy tensor to variable called x_skip\n",
    "    x_skip = x\n",
    "    # Layer 1\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Layer 2\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    # Add Residue\n",
    "    x = tf.keras.layers.Add()([x, x_skip])     \n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def convolutional_block(x, filter):\n",
    "    # copy tensor to variable called x_skip\n",
    "    x_skip = x\n",
    "    # Layer 1\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same', strides = (2,2))(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Layer 2\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    # Processing Residue with conv(1,1)\n",
    "    x_skip = tf.keras.layers.Conv2D(filter, (1,1), strides = (2,2))(x_skip)\n",
    "    # Add Residue\n",
    "    x = tf.keras.layers.Add()([x, x_skip])     \n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def ResNet34(shape = (32, 32, 3), classes = 10):\n",
    "    # Step 1 (Setup Input Layer)\n",
    "    x_input = tf.keras.layers.Input(shape)\n",
    "    x = tf.keras.layers.ZeroPadding2D((3, 3))(x_input)\n",
    "    # Step 2 (Initial Conv layer along with maxPool)\n",
    "    x = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    # Define size of sub-blocks and initial filter size\n",
    "    block_layers = [3, 4, 6, 3]\n",
    "    filter_size = 64\n",
    "    # Step 3 Add the Resnet Blocks\n",
    "    for i in range(4):\n",
    "        if i == 0:\n",
    "            # For sub-block 1 Residual/Convolutional block not needed\n",
    "            for j in range(block_layers[i]):\n",
    "                x = identity_block(x, filter_size)\n",
    "        else:\n",
    "            # One Residual/Convolutional Block followed by Identity blocks\n",
    "            # The filter size will go on increasing by a factor of 2\n",
    "            filter_size = filter_size*2\n",
    "            x = convolutional_block(x, filter_size)\n",
    "            for j in range(block_layers[i] - 1):\n",
    "                x = identity_block(x, filter_size)\n",
    "    # Step 4 End Dense Network\n",
    "    x = tf.keras.layers.AveragePooling2D((2,2), padding = 'same')(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n",
    "    x = tf.keras.layers.Dense(classes, activation = 'softmax')(x)\n",
    "    model = tf.keras.models.Model(inputs = x_input, outputs = x, name = \"ResNet34\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.1, 13050, 0.94, staircase=False,\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=lr,\n",
    "    weight_decay=0.0005\n",
    ")\n",
    "model = ResNet34((200,200,3), num_labels)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2175/2175 [==============================] - 7477s 3s/step - loss: 0.7883 - accuracy: 0.7527 - val_loss: 1.8311 - val_accuracy: 0.6761\n",
      "Epoch 2/3\n",
      "2175/2175 [==============================] - 7539s 3s/step - loss: 0.0899 - accuracy: 0.9706 - val_loss: 2.9892 - val_accuracy: 0.4700\n",
      "Epoch 3/3\n",
      "2175/2175 [==============================] - 7802s 4s/step - loss: 0.0557 - accuracy: 0.9825 - val_loss: 0.3265 - val_accuracy: 0.9063\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(ds_train, validation_data=ds_test, epochs=3, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 1/3\n",
    "\n",
    "2175/2175 [==============================] - 7477s 3s/step - loss: 0.7883 - accuracy: 0.7527 - val_loss: 1.8311 - val_accuracy: 0.6761\n",
    "\n",
    "Epoch 2/3\n",
    "\n",
    "2175/2175 [==============================] - 7539s 3s/step - loss: 0.0899 - accuracy: 0.9706 - val_loss: 2.9892 - val_accuracy: 0.4700\n",
    "\n",
    "Epoch 3/3\n",
    "\n",
    "2175/2175 [==============================] - 7802s 4s/step - loss: 0.0557 - accuracy: 0.9825 - val_loss: 0.3265 - val_accuracy: 0.9063"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 36). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Res_Net_asl_trained_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Res_Net_asl_trained_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"Res_Net_asl_trained_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28 files belonging to 28 classes.\n"
     ]
    }
   ],
   "source": [
    "ds_val = tf.keras.utils.image_dataset_from_directory(\"asl_alphabet_test\", image_size=(200,200), seed=128, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet34\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 200, 200, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPadding2D)  (None, 206, 206, 3)  0          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 103, 103, 64  9472        ['zero_padding2d[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 103, 103, 64  256        ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 103, 103, 64  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 52, 52, 64)   0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 52, 52, 64)   36928       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 52, 52, 64)  256         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 52, 52, 64)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 52, 52, 64)   36928       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 52, 52, 64)  256         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 52, 52, 64)   0           ['batch_normalization_2[0][0]',  \n",
      "                                                                  'max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 52, 52, 64)   0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 52, 52, 64)   36928       ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 52, 52, 64)  256         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 52, 52, 64)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 52, 52, 64)   36928       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 52, 52, 64)  256         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 52, 52, 64)   0           ['batch_normalization_4[0][0]',  \n",
      "                                                                  'activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 52, 52, 64)   0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 52, 52, 64)   36928       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 52, 52, 64)  256         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 52, 52, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 52, 52, 64)   36928       ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 52, 52, 64)  256         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 52, 52, 64)   0           ['batch_normalization_6[0][0]',  \n",
      "                                                                  'activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 52, 52, 64)   0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 26, 26, 128)  73856       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 26, 26, 128)  512        ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 26, 26, 128)  0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 26, 26, 128)  147584      ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 26, 26, 128)  512        ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 26, 26, 128)  8320        ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 26, 26, 128)  0           ['batch_normalization_8[0][0]',  \n",
      "                                                                  'conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 26, 26, 128)  0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 26, 26, 128)  147584      ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 26, 26, 128)  512        ['conv2d_10[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 26, 26, 128)  0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 26, 26, 128)  147584      ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 26, 26, 128)  512        ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 26, 26, 128)  0           ['batch_normalization_10[0][0]', \n",
      "                                                                  'activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 26, 26, 128)  0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 26, 26, 128)  147584      ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 26, 26, 128)  512        ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 26, 26, 128)  0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 26, 26, 128)  147584      ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 26, 26, 128)  512        ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 26, 26, 128)  0           ['batch_normalization_12[0][0]', \n",
      "                                                                  'activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 26, 26, 128)  0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 26, 26, 128)  147584      ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 26, 26, 128)  512        ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 26, 26, 128)  0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 26, 26, 128)  147584      ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 26, 26, 128)  512        ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 26, 26, 128)  0           ['batch_normalization_14[0][0]', \n",
      "                                                                  'activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 26, 26, 128)  0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 13, 13, 256)  295168      ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 13, 13, 256)  1024       ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 13, 13, 256)  0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 13, 13, 256)  590080      ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 13, 13, 256)  1024       ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 13, 13, 256)  33024       ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 13, 13, 256)  0           ['batch_normalization_16[0][0]', \n",
      "                                                                  'conv2d_18[0][0]']              \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 13, 13, 256)  0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 13, 13, 256)  590080      ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 13, 13, 256)  1024       ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 13, 13, 256)  0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 13, 13, 256)  590080      ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 13, 13, 256)  1024       ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 13, 13, 256)  0           ['batch_normalization_18[0][0]', \n",
      "                                                                  'activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 13, 13, 256)  0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 13, 13, 256)  590080      ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 13, 13, 256)  1024       ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 13, 13, 256)  0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 13, 13, 256)  590080      ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 13, 13, 256)  1024       ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 13, 13, 256)  0           ['batch_normalization_20[0][0]', \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 13, 13, 256)  0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 13, 13, 256)  590080      ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 13, 13, 256)  1024       ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 13, 13, 256)  0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 13, 13, 256)  590080      ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 13, 13, 256)  1024       ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 13, 13, 256)  0           ['batch_normalization_22[0][0]', \n",
      "                                                                  'activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 13, 13, 256)  0           ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 13, 13, 256)  590080      ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 13, 13, 256)  1024       ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 13, 13, 256)  0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 13, 13, 256)  590080      ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 13, 13, 256)  1024       ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 13, 13, 256)  0           ['batch_normalization_24[0][0]', \n",
      "                                                                  'activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 13, 13, 256)  0           ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 13, 13, 256)  590080      ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 13, 13, 256)  1024       ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 13, 13, 256)  0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 13, 13, 256)  590080      ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 13, 13, 256)  1024       ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 13, 13, 256)  0           ['batch_normalization_26[0][0]', \n",
      "                                                                  'activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 13, 13, 256)  0           ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 7, 7, 512)    1180160     ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 7, 7, 512)   2048        ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 7, 7, 512)    0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 7, 7, 512)    2359808     ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 7, 7, 512)   2048        ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 7, 7, 512)    131584      ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 7, 7, 512)    0           ['batch_normalization_28[0][0]', \n",
      "                                                                  'conv2d_31[0][0]']              \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 7, 7, 512)    0           ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 7, 7, 512)    2359808     ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 7, 7, 512)   2048        ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 7, 7, 512)    0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 7, 7, 512)    2359808     ['activation_29[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 7, 7, 512)   2048        ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 7, 7, 512)    0           ['batch_normalization_30[0][0]', \n",
      "                                                                  'activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 7, 7, 512)    0           ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 7, 7, 512)    2359808     ['activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 7, 7, 512)   2048        ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 7, 7, 512)    0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 7, 7, 512)    2359808     ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 7, 7, 512)   2048        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 7, 7, 512)    0           ['batch_normalization_32[0][0]', \n",
      "                                                                  'activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 7, 7, 512)    0           ['add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 4, 4, 512)   0           ['activation_32[0][0]']          \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 8192)         0           ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          4194816     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 29)           14877       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25,516,317\n",
      "Trainable params: 25,501,085\n",
      "Non-trainable params: 15,232\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "saved_model = tf.keras.models.load_model('Res_Net_asl_trained_model')\n",
    "\n",
    "# Check its architecture\n",
    "saved_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 1s - loss: 1.2533 - accuracy: 0.8929 - 1s/epoch - 1s/step\n",
      "Restored model, accuracy: 89.29%\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "(28, 29)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the restored model\n",
    "loss, acc = saved_model.evaluate(ds_val, verbose=2)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
    "\n",
    "print(saved_model.predict(ds_val).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba638da1d2555046f6c036f3b55f96640e14b9ae1bacb866420559fab20bdea2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
